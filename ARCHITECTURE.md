
# DÂ³ Deepfake Detection API - Deployment Architecture

## ğŸ“ Files Created for Deployment

```
D3/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ .env                         âœ… Production configuration
â”‚   â”œâ”€â”€ app.py                       âœ… Flask application
â”‚   â”œâ”€â”€ routes/                      âœ… API endpoints
â”‚   â”œâ”€â”€ services/                    âœ… Business logic
â”‚   â””â”€â”€ utils/                       âœ… Helper functions
â”‚
â”œâ”€â”€ gunicorn_config.py               ğŸ†• WSGI server config
â”œâ”€â”€ d3-api.service                   ğŸ†• Systemd service
â”œâ”€â”€ d3-api-nginx.conf                ğŸ†• Nginx configuration
â”œâ”€â”€ deploy.sh                        ğŸ†• Automated deployment script
â”œâ”€â”€ check_deployment.sh              ğŸ†• Pre-deployment checker
â”œâ”€â”€ DEPLOYMENT.md                    ğŸ†• Complete deployment guide
â”œâ”€â”€ DEPLOYMENT_SUMMARY.md            ğŸ†• Quick overview
â””â”€â”€ QUICK_REFERENCE.md               ğŸ†• Command reference
```

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Internet / Users                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                         [Port 80/443]
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Nginx (Reverse Proxy)                       â”‚
â”‚  â€¢ Load balancing                                                â”‚
â”‚  â€¢ SSL/TLS termination                                           â”‚
â”‚  â€¢ Request routing                                               â”‚
â”‚  â€¢ Static file serving                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                         [Port 6000]
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Gunicorn (WSGI Server)                        â”‚
â”‚  â€¢ 2 worker processes                                            â”‚
â”‚  â€¢ 2 threads per worker                                          â”‚
â”‚  â€¢ 600s timeout                                                  â”‚
â”‚  â€¢ Process management                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Flask API (app.py)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Routes:                                                   â”‚  â”‚
â”‚  â”‚  â€¢ /health          - Health check                        â”‚  â”‚
â”‚  â”‚  â€¢ /predict         - Single image                        â”‚  â”‚
â”‚  â”‚  â€¢ /predict/batch   - Multiple images                     â”‚  â”‚
â”‚  â”‚  â€¢ /predict/video   - Video analysis                      â”‚  â”‚
â”‚  â”‚  â€¢ /predictions     - Query results                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚              â”‚              â”‚
       â”‚              â”‚              â”‚              â”‚
       â–¼              â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  D3 Model   â”‚ â”‚  MinIO   â”‚ â”‚ PostgreSQL â”‚ â”‚  GPU (CUDA)  â”‚
â”‚  (PyTorch)  â”‚ â”‚ Storage  â”‚ â”‚  Database  â”‚ â”‚   Inference  â”‚
â”‚             â”‚ â”‚          â”‚ â”‚            â”‚ â”‚              â”‚
â”‚ â€¢ ViT-L/14  â”‚ â”‚ â€¢ Images â”‚ â”‚ â€¢ Results  â”‚ â”‚ â€¢ NVIDIA GPU â”‚
â”‚ â€¢ CLIP      â”‚ â”‚ â€¢ Videos â”‚ â”‚ â€¢ Metadata â”‚ â”‚ â€¢ Memory Opt â”‚
â”‚ â€¢ Fine-tune â”‚ â”‚ â€¢ JSON   â”‚ â”‚ â€¢ History  â”‚ â”‚ â€¢ Batch Proc â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Request Flow

### Image Prediction Flow
```
1. Client â†’ POST /predict (with image file)
                â†“
2. Nginx â†’ Receives request, forwards to Gunicorn
                â†“
3. Gunicorn â†’ Spawns worker, passes to Flask
                â†“
4. Flask â†’ Validates image, calls InferenceService
                â†“
5. InferenceService â†’ Loads image, preprocesses
                â†“
6. D3Model â†’ GPU inference, returns prediction
                â†“
7. MinioService â†’ Uploads result JSON
                â†“
8. DatabaseService â†’ Stores metadata in PostgreSQL
                â†“
9. Flask â†’ Returns JSON response to client
   {
     "prediction": "fake",
     "confidence": 0.9234,
     "result_url": "https://minio.../result.json"
   }
```

### Video Prediction Flow
```
1. Client â†’ POST /predict/video (with video file)
                â†“
2. Nginx â†’ Receives large file (500MB max), forwards
                â†“
3. Gunicorn â†’ Extended timeout (600s), passes to Flask
                â†“
4. Flask â†’ Saves video temporarily
                â†“
5. InferenceService â†’ Extracts frames
                â†“
6. For each frame batch:
   â”œâ”€ Preprocess frames
   â”œâ”€ GPU inference
   â””â”€ Aggregate predictions
                â†“
7. Calculate final prediction (voting/averaging)
                â†“
8. MinioService â†’ Upload video + frame results
                â†“
9. DatabaseService â†’ Store in PostgreSQL
                â†“
10. Flask â†’ Return detailed results
    {
      "prediction": "fake",
      "confidence": 0.8765,
      "frames_analyzed": 120,
      "frame_predictions": [...]
    }
```

## ğŸ”§ Component Responsibilities

### Nginx
- **Port**: 80 (HTTP), 443 (HTTPS)
- **Role**: Entry point, load balancing, SSL termination
- **Config**: `/etc/nginx/sites-available/d3-api`
- **Logs**: `/var/log/nginx/d3-api-*.log`

### Gunicorn
- **Port**: 6000 (internal)
- **Role**: WSGI server, process management
- **Config**: `gunicorn_config.py`
- **Workers**: 2 processes, 2 threads each
- **Logs**: `logs/access.log`, `logs/error.log`

### Flask API
- **Framework**: Flask + Blueprint routing
- **Role**: Business logic, request handling
- **Structure**:
  - `app.py` - Main application
  - `routes/` - Endpoint definitions
  - `services/` - Core logic (inference, storage, DB)
  - `utils/` - Helper functions

### D3 Model
- **Architecture**: Dual-branch CNN + Transformer
- **Backbone**: CLIP ViT-L/14
- **Weights**: Fine-tuned on WildRF dataset
- **Device**: CUDA GPU (automatic fallback to CPU)
- **Memory**: ~2GB GPU RAM per worker

### MinIO
- **Port**: 9000 (API), 9001 (Console)
- **Role**: Object storage for results
- **Buckets**: 
  - `d3-results` - JSON predictions
  - `d3-videos` - Uploaded videos
  - `d3-frames` - Frame-level results

### PostgreSQL
- **Port**: 5432
- **Role**: Metadata storage, query interface
- **Tables**:
  - `predictions` - All prediction records
  - `video_predictions` - Video-specific data

## ğŸ“Š Resource Usage

### CPU
```
Nginx:     ~1-2% idle, 10-20% under load
Gunicorn:  ~5-10% per worker idle
Python:    ~20-30% during inference
Total:     ~30-50% under normal load
```

### Memory (RAM)
```
Nginx:        ~50 MB
Gunicorn:     ~200 MB per worker
Flask App:    ~500 MB per worker
D3 Model:     ~2 GB (loaded once per worker)
Total:        ~3-5 GB for 2 workers
```

### GPU Memory
```
Model Weights:     ~2 GB
Inference Buffer:  ~500 MB - 2 GB (depends on batch size)
Total per worker:  ~2-4 GB
Recommended:       8 GB+ GPU for production
```

### Disk Space
```
Model Checkpoint:    ~500 MB
Application Code:    ~100 MB
Logs (per day):     ~10-50 MB
Videos (temporary): Variable
MinIO Storage:      Variable
PostgreSQL DB:      ~10 MB + growth
```

## âš¡ Performance Characteristics

### Latency
```
Single Image:   ~100-200ms (GPU inference)
                ~50ms (preprocessing)
                ~50ms (post-processing)
                Total: ~200-300ms

Video (30s):    ~5-15 seconds (depends on frames sampled)
                ~100-200ms per frame
                ~1-2s aggregation
```

### Throughput
```
Single Worker:     ~3-5 requests/second (images)
Two Workers:       ~6-10 requests/second
Batch Processing:  ~20-30 images/second

Video:             ~1 video/minute (30s videos)
                   ~2-4 videos/minute (with optimizations)
```

### Scalability
```
Vertical (Single Server):
  - Limited by GPU memory
  - Max 2-4 workers per GPU (8-16GB VRAM)
  
Horizontal (Multiple Servers):
  - Add more GPU servers
  - Use Nginx load balancing
  - Share MinIO + PostgreSQL
```

## ğŸ›¡ï¸ Security Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Internet (Untrusted)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
         [Firewall - UFW]
                  â”‚ Allow: 80, 443
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Nginx                                       â”‚
â”‚ â€¢ Rate limiting                             â”‚
â”‚ â€¢ Request validation                        â”‚
â”‚ â€¢ SSL/TLS encryption                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
         [Internal Network]
                  â”‚ Port 6000 (localhost only)
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gunicorn + Flask                            â”‚
â”‚ â€¢ Input validation                          â”‚
â”‚ â€¢ File size limits                          â”‚
â”‚ â€¢ MIME type checking                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Application Services                        â”‚
â”‚ â€¢ Secure file handling                      â”‚
â”‚ â€¢ SQL injection prevention                  â”‚
â”‚ â€¢ XSS protection                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ˆ Monitoring Points

### Application Metrics
- Request count per endpoint
- Response times (p50, p95, p99)
- Error rates (4xx, 5xx)
- Prediction distribution (real vs fake)

### System Metrics
- CPU usage per process
- Memory consumption
- GPU utilization
- GPU memory usage
- Disk I/O
- Network bandwidth

### Business Metrics
- Total predictions per day
- Video vs image ratio
- Average confidence scores
- Storage usage growth

## ğŸ”„ Deployment Workflow

```
1. Development
   â”œâ”€ Code changes
   â”œâ”€ Local testing
   â””â”€ Commit to git

2. Pre-Deployment
   â”œâ”€ Run: ./check_deployment.sh
   â”œâ”€ Verify all checks pass
   â””â”€ Review configuration

3. Deployment
   â”œâ”€ Run: ./deploy.sh
   â”œâ”€ Install services
   â”œâ”€ Configure Nginx
   â””â”€ Start systemd service

4. Verification
   â”œâ”€ Check service status
   â”œâ”€ Test endpoints
   â”œâ”€ Monitor logs
   â””â”€ GPU monitoring

5. Monitoring
   â”œâ”€ Watch logs
   â”œâ”€ Track metrics
   â”œâ”€ Check performance
   â””â”€ User feedback

6. Maintenance
   â”œâ”€ Log rotation
   â”œâ”€ Database cleanup
   â”œâ”€ Update dependencies
   â””â”€ Security patches
```

## ğŸ¯ Deployment Checklist

```
â–¡ Prerequisites
  â–¡ GPU available and working
  â–¡ Conda environment created
  â–¡ Model checkpoint downloaded
  â–¡ MinIO service running
  â–¡ PostgreSQL configured

â–¡ Configuration
  â–¡ .env file updated
  â–¡ Paths verified
  â–¡ Credentials set
  â–¡ Port numbers configured

â–¡ Installation
  â–¡ Gunicorn installed
  â–¡ Nginx installed
  â–¡ Systemd service created
  â–¡ Firewall configured

â–¡ Testing
  â–¡ Health check passes
  â–¡ Image prediction works
  â–¡ Video prediction works
  â–¡ Database queries work

â–¡ Production
  â–¡ SSL certificate obtained
  â–¡ Monitoring setup
  â–¡ Log rotation configured
  â–¡ Backups automated

â–¡ Documentation
  â–¡ API endpoints documented
  â–¡ Team trained
  â–¡ Runbook created
  â–¡ Contact info updated
```

---

**ğŸ‰ Your DÂ³ API is production-ready with GPU-accelerated inference!**

Start deployment: `./check_deployment.sh && ./deploy.sh`
